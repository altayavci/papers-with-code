{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPoZ17tyOLH9HpUqb8zhSp3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/altayavci/papers-with-code/blob/dev/bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "ngJdRNI3wT6R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WtjqiweYw0O1",
        "outputId": "d2850f8c-3311-44d6-8865-db5eeb137418"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/data_tiny.csv\")"
      ],
      "metadata": {
        "id": "Zp8MMWQvw8mo"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts, labels = dataset.text.values.tolist(), dataset.target.values.tolist()"
      ],
      "metadata": {
        "id": "EBlK9Gs8xAE6"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kA_gDxNJ__9G",
        "outputId": "765b1816-46bf-497d-c105-78a0391935f0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'first hand'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)"
      ],
      "metadata": {
        "id": "TKuD2M5GxDKO"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TQ6E3kj_6kn",
        "outputId": "e960ee21-91c1-496b-b8a3-61d11403cb73"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")"
      ],
      "metadata": {
        "id": "WQSuBcmIxExu"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "id": "wEC79KxYxGCd"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_train, inputs_val, labels_train, labels_val = train_test_split(inputs.input_ids, labels, test_size=0.33)"
      ],
      "metadata": {
        "id": "FF8kV8szxJ_h"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(inputs_train, labels_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "G2IjITzdxOS3"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = TensorDataset(inputs_val, labels_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "pxXKJWL7yiEY"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk90VMYxxP3-",
        "outputId": "816437d7-9970-4141-fc9e-f2d7c9e5cae9"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"dbmdz/bert-base-turkish-cased\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "douc8Q6dxXal",
        "outputId": "2b6f1610-240f-4cb9-e547-b54b27383b86"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "DVymyrRkxTB9"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "loss_function = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "EqzheScpxUHr"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3"
      ],
      "metadata": {
        "id": "nEAxi71cxgvl"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_loss_min = np.Inf\n",
        "train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    model.train()\n",
        "    for batch_inputs, batch_labels in tqdm(train_loader,total=len(train_loader)):\n",
        "        batch_inputs, batch_labels = batch_inputs.to(device), batch_labels.to(device)\n",
        "        outputs = model(batch_inputs, labels=batch_labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        preds = torch.argmax(outputs.logits, dim = 1)\n",
        "        correct += torch.sum(preds == batch_labels).item()\n",
        "        total += batch_labels.size(0)\n",
        "\n",
        "    train_acc.append(100 * correct / total)\n",
        "    train_loss.append(running_loss / len(train_loader))\n",
        "\n",
        "\n",
        "    val_true, val_pred = [], []\n",
        "    running_loss, correct, total = 0.0, 0.0, 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_inputs, batch_labels in tqdm(val_loader,total=len(val_loader)):\n",
        "           batch_inputs, batch_labels = batch_inputs.to(device), batch_labels.to(device)\n",
        "           outputs = model(batch_inputs, labels=batch_labels)\n",
        "\n",
        "           loss = outputs.loss\n",
        "           running_loss += loss.item()\n",
        "           preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "           val_true.extend(batch_labels.data.cpu().numpy())\n",
        "           val_pred.extend(preds.data.cpu().numpy())\n",
        "\n",
        "           correct += torch.sum(preds == batch_labels).item()\n",
        "           total += batch_labels.size(0)\n",
        "\n",
        "        val_acc.append(100 * correct / total)\n",
        "        val_loss.append(running_loss / len(val_loader))\n",
        "\n",
        "\n",
        "    network_learned = running_loss < valid_loss_min\n",
        "    if network_learned:\n",
        "            valid_loss_min = running_loss\n",
        "            torch.save(model.state_dict(), os.path.join(\"/content/\", 'best.pt'))\n",
        "            print(\"Model has learned !\\n\")\n",
        "\n",
        "\n",
        "            plt.figure(figsize = (15, 13), facecolor = 'silver', edgecolor = 'gray')\n",
        "\n",
        "            cm = confusion_matrix(val_true, val_pred, labels=[0,1])\n",
        "            ax= plt.subplot()\n",
        "            sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
        "            ax.set_xlabel('Predicted labels')\n",
        "            ax.set_ylabel('True labels')\n",
        "            ax.set_title('Confusion Matrix')\n",
        "            ax.xaxis.set_ticklabels([\"first hand\", \"second hand\"])\n",
        "            ax.yaxis.set_ticklabels([\"first hand\", \"second hand\"])\n",
        "            plt.savefig(os.path.join(\"/content/\", 'confussion.png'))\n",
        "            plt.close()\n",
        "\n",
        "            plt.figure(figsize = (15, 12), facecolor = 'silver', edgecolor = 'gray')\n",
        "            cr = classification_report(val_true, val_pred,\n",
        "                                   target_names = [\"first hand\", \"second hand\"],\n",
        "                                   output_dict = True)\n",
        "\n",
        "            sns.heatmap(pd.DataFrame(cr).iloc[:-1, :].T, annot=True)\n",
        "            plt.savefig(os.path.join(\"/content/\", 'report.png'))\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmgp-xEqxibG",
        "outputId": "d30c3f39-840a-4e1d-a338-4d90f32f47d9"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [02:23<00:00,  1.56s/it]\n",
            "100%|██████████| 46/46 [00:24<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has learned !\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [02:23<00:00,  1.56s/it]\n",
            "100%|██████████| 46/46 [00:24<00:00,  1.88it/s]\n",
            "100%|██████████| 92/92 [02:23<00:00,  1.56s/it]\n",
            "100%|██████████| 46/46 [00:24<00:00,  1.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcN6XMeRFdXN",
        "outputId": "15ea8b9c-8969-4527-a782-7b96bc5a917f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[96.44079397672827, 97.80971937029432, 98.01505817932923]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHT8ej1nFhym",
        "outputId": "ea91bf1b-3a1b-4f69-ebbd-b4f203ed6919"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10196706698701272, 0.06213869106874842, 0.05582108931696933]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tejH-PMhFprx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}